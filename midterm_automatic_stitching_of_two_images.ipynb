{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Choose two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_r = cv2.imread('./case3/image_right.jpg')  # 오른쪽 사진\n",
    "image_l = cv2.imread('./case3/image_left.jpg')  # 왼쪽 사진\n",
    "\n",
    "gray_r = cv2.cvtColor(image_r, cv2.COLOR_BGR2GRAY)\n",
    "gray_l = cv2.cvtColor(image_l, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. compute ORB keypoint and descriptors (opencv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ORB \n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# calculate the keypoints, descriptors \n",
    "keypoint_l, descriptor_l = orb.detectAndCompute(gray_l, None)\n",
    "keypoint_r, descriptor_r = orb.detectAndCompute(gray_r, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. apply Bruteforce matching with Hamming distance (opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knnMatch using BF-Hamming\n",
    "bfmatcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = bfmatcher.match(descriptor_l, descriptor_r)\n",
    "\n",
    "# sort the result of matching and save good matching\n",
    "sorted_matches = sorted(matches, key=lambda x: x.distance)\n",
    "good_matches = sorted_matches[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. implement RANSAC algorithm to compute the homography matrix. (DIY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_random(src_pts, dst_pts):\n",
    "    random_indices = np.random.choice(len(src_pts), 4)\n",
    "    return np.array([src_pts[i] for i in random_indices]), np.array([dst_pts[i] for i in random_indices])\n",
    "\n",
    "\n",
    "def find_homography_ransac(src_pts, dst_pts, good_src_pts, good_dst_pts,\n",
    "                           threshold=100, iter_limit=2000):\n",
    "    \n",
    "    iter = 0\n",
    "    best_inlier = 0\n",
    "    best_H = 0\n",
    "\n",
    "    while best_inlier < threshold and iter < iter_limit:\n",
    "        iter += 1\n",
    "        src, dst = choice_random(good_src_pts, good_dst_pts)\n",
    "        H = calculate_homography(src, dst)\n",
    "        \n",
    "        inlier = 0\n",
    "        for j in range(len(src_pts)):\n",
    "            x = np.transpose(\n",
    "                np.matrix([src_pts[j][0], src_pts[j][1], 1]))\n",
    "            u = np.transpose(\n",
    "                np.matrix([dst_pts[j][0], dst_pts[j][1], 1]))\n",
    "\n",
    "            # x_hat is estimation result.\n",
    "            x_hat = np.dot(H, x)\n",
    "            x_hat = (1/x_hat.item(2))*x_hat\n",
    "\n",
    "            e = u - x_hat\n",
    "            d = np.linalg.norm(e)\n",
    "            \n",
    "            if d < 5:\n",
    "                inlier += 1\n",
    "           \n",
    "            if best_inlier < inlier:\n",
    "                best_inlier = inlier\n",
    "                best_H = H\n",
    "           \n",
    "    return best_H\n",
    "\n",
    "\n",
    "def calculate_homography(src_points, dst_points):\n",
    "    A = []\n",
    "    for i in range(len(src_points)):\n",
    "        x, y = src_points[i][0], src_points[i][1]\n",
    "        u, v = dst_points[i][0], dst_points[i][1]\n",
    "        A.append([x, y, 1, 0, 0, 0, -x*u, -u*y, -u])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y, -v])\n",
    "\n",
    "    A = np.array(A)\n",
    "    _, _, vt = np.linalg.svd(A)\n",
    "    \n",
    "    H = np.reshape(vt[-1], (3, 3))\n",
    "    H = (1 / H.item(8)) * H\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_pts = np.float32(\n",
    "    [keypoint_l[m.queryIdx].pt for m in matches]).reshape((-1, 2))\n",
    "src_pts = np.float32(\n",
    "    [keypoint_r[m.trainIdx].pt for m in matches]).reshape((-1, 2))\n",
    "\n",
    "good_dst_pts = np.float32(\n",
    "    [keypoint_l[m.queryIdx].pt for m in good_matches]).reshape((-1, 2))\n",
    "good_src_pts = np.float32(\n",
    "    [keypoint_r[m.trainIdx].pt for m in good_matches]).reshape((-1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.28514209e-01  4.88237929e-02  2.44203887e+03]\n",
      " [-2.75595597e-01  7.74459640e-01  5.03591298e+02]\n",
      " [-9.43986186e-05 -1.20242943e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "H = find_homography_ransac(src_pts, dst_pts,\n",
    "                          good_src_pts, good_dst_pts)\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. prepare a panorama image of larger size (DIY) / 6. warp two images to the panorama image using the homography matrix (DIY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_panorama(image_l, image_r, H):\n",
    "    \n",
    "    # warping\n",
    "    src_locs = []\n",
    "    for x in tqdm(range(image_r.shape[1])):\n",
    "        for y in range(image_l.shape[0]):\n",
    "            loc = [x, y, 1]\n",
    "            src_locs.append(loc)\n",
    "    src_locs = np.array(src_locs).transpose()\n",
    "    \n",
    "    dst_locs = np.matmul(H, src_locs)\n",
    "    dst_locs = dst_locs / dst_locs[2, :]\n",
    "    dst_locs = dst_locs[:2, :]\n",
    "    src_locs = src_locs[:2, :]\n",
    "    dst_locs = np.round(dst_locs, 0).astype(int)\n",
    "    \n",
    "    height, width, _ = image_l.shape\n",
    "    \n",
    "    # prepare a panorama image\n",
    "    result = np.zeros((height, width * 2, 3), dtype=int)\n",
    "    for src, dst in tqdm(zip(src_locs.transpose(), dst_locs.transpose())):\n",
    "        if dst[0] < 0 or dst[1] < 0 or dst[0] >= width*2 or dst[1] >= height:\n",
    "            continue\n",
    "        result[dst[1], dst[0]] = image_r[src[1], src[0]]\n",
    "    result[0: height, 0: width] = image_l\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5712 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5712/5712 [00:11<00:00, 494.73it/s]\n",
      "24470208it [00:48, 507942.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panorama_result = create_panorama(image_l, image_r, H) # forward mapping\n",
    "cv2.imwrite('result_forward.png', panorama_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional attempt: Backward mapping, Interpolation\n",
    "\n",
    "검정색 빗살이 쳐지는 현상은 이미지가 변환되면서 이전 point들이 모든 pixel영역을 채워주지 못하기 때문이며, 'Backward mapping'과 'Interpolation'을 통해 빗살 무늬 현상을 해결하고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_without_interpolation(image, H, output_shape):\n",
    "    height, width = image.shape[:2]\n",
    "    warped_image = np.zeros(\n",
    "        (output_shape[1], output_shape[0], image.shape[2]), dtype=image.dtype)\n",
    "\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    for y_out in range(output_shape[1]):\n",
    "        for x_out in range(output_shape[0]):\n",
    "            point = np.dot(H_inv, np.array([x_out, y_out, 1]))\n",
    "            point = point / point[2]\n",
    "\n",
    "            x_in, y_in = int(point[0]), int(point[1])\n",
    "\n",
    "            if 0 <= x_in < width and 0 <= y_in < height:\n",
    "                warped_image[y_out, x_out] = image[y_in, x_in]\n",
    "\n",
    "    return warped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_with_interpolation(image, H, output_shape):\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    warped_image = np.zeros((output_shape[1], output_shape[0], image.shape[2]), dtype=image.dtype)\n",
    "\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    for y_out in range(output_shape[1]):\n",
    "        for x_out in range(output_shape[0]):\n",
    "            # transform the output coordinates to input coordinates using an inverse transformation\n",
    "            point = np.dot(H_inv, np.array([x_out, y_out, 1]))\n",
    "            point = point / point[2]\n",
    "\n",
    "            x_in, y_in = int(point[0]), int(point[1])\n",
    "\n",
    "            # checks if it is within the input image boundaries\n",
    "            if 0 <= x_in < width-1 and 0 <= y_in < height-1:\n",
    "                # bilinear interpolation\n",
    "                dx, dy = point[0] - x_in, point[1] - y_in\n",
    "                for channel in range(image.shape[2]):\n",
    "                    if 0 <= x_in+1 < width and 0 <= y_in+1 < height:\n",
    "                        warped_image[y_out, x_out, channel] = (\n",
    "                            (1 - dx) * (1 - dy) * image[y_in, x_in, channel] +\n",
    "                            dx * (1 - dy) * image[y_in, x_in + 1, channel] +\n",
    "                            (1 - dx) * dy * image[y_in + 1, x_in, channel] +\n",
    "                            dx * dy * image[y_in + 1, x_in + 1, channel]\n",
    "                        )\n",
    "\n",
    "    return warped_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bw_wo_ip = backward_without_interpolation(image_r, H, (image_r.shape[1] + image_l.shape[1], image_r.shape[0]))\n",
    "result_bw_wo_ip[0: image_r.shape[0], 0: image_l.shape[1]] = image_l\n",
    "cv2.imwrite('result_backward_wo_interpolation.png', result_bw_wo_ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bw_w_ip = backward_with_interpolation(image_r, H, (image_r.shape[1] + image_l.shape[1], image_r.shape[0]))\n",
    "result_bw_w_ip[0: image_r.shape[0], 0: image_l.shape[1]] = image_l\n",
    "cv2.imwrite('result_backward_w_interpolation.png', result_bw_w_ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"result_usingcv = cv2.warpPerspective(image_r, H, (image_r.shape[1] + image_l.shape[1], image_r.shape[0]))\\nresult_usingcv[0 : image_r.shape[0], 0 : image_l.shape[1]] = image_l\\ncv2.imwrite('result_usingcv.png', result_usingcv)\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (참고) 위의 코드를 opencv 라이브러리를 이용해서 구현하는 방법\n",
    "'''result_usingcv = cv2.warpPerspective(image_r, H, (image_r.shape[1] + image_l.shape[1], image_r.shape[0]))\n",
    "result_usingcv[0 : image_r.shape[0], 0 : image_l.shape[1]] = image_l\n",
    "cv2.imwrite('result_usingcv.png', result_usingcv)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
